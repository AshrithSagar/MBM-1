{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AF2_multi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshrithSagar/MBM-1/blob/main/AF2_multi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "##ColabFold: AlphaFold2 using MMseqs2 || Run Multiples sequences\n",
        "\n",
        "*Run AF2 with multiple sequences sequentially*\n",
        "\n",
        "Easy to use protein structure and complex prediction using [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) and [Alphafold2-multimer](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1). Sequence alignments/templates are generated through [MMseqs2](mmseqs.com) and [HHsearch](https://github.com/soedinglab/hh-suite). For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold) and read our manuscript. Old versions: [v1.0](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.0-alpha/AlphaFold2.ipynb), [v1.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.1-premultimer/AlphaFold2.ipynb), [v1.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.2.0/AlphaFold2.ipynb), [v1.3](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.3.0/AlphaFold2.ipynb)\n",
        "\n",
        "[Mirdita M, Schütze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1) \n",
        "\n",
        "-----------------\n",
        "- <b><font color='green'>2022/07/13: The move of the ColabFold MSA server to [KOBIC](https://kobic.re.kr) is now complete. MSA generation was accelerated with multiple threads and databases were updated to UniRef30 2022_02 and PDB/PDB70 220313.</font></b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOblAo-xetgx",
        "cellView": "form"
      },
      "source": [
        "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os.path\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "query_sequence = 'SKNKCNEWDTLTSWRVGDSNSKTDAKGHFLQNLCTGNGKG' #@param {type:\"string\"}\n",
        "#@markdown  - Use `:` to specify inter-protein chainbreaks for **modeling complexes** (supports homo- and hetro-oligomers). For example **PI...SK:PI...SK** for a homodimer\n",
        "\n",
        "# remove whitespaces\n",
        "query_sequence = \"\".join(query_sequence.split())\n",
        "\n",
        "jobname = 'Variant_1_12_2_4_1' #@param {type:\"string\"}\n",
        "# remove whitespaces\n",
        "basejobname = \"\".join(jobname.split())\n",
        "basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "jobname = add_hash(basejobname, query_sequence)\n",
        "while os.path.isfile(f\"{jobname}.csv\"):\n",
        "  jobname = add_hash(basejobname, ''.join(random.sample(query_sequence,len(query_sequence))))\n",
        "\n",
        "with open(f\"{jobname}.csv\", \"w\") as text_file:\n",
        "    text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "queries_path=f\"{jobname}.csv\"\n",
        "\n",
        "# number of models to use\n",
        "use_amber = True #@param {type:\"boolean\"}\n",
        "template_mode = \"none\" #@param [\"none\", \"pdb70\",\"custom\"]\n",
        "#@markdown - \"none\" = no template information is used, \"pdb70\" = detect templates in pdb70, \"custom\" - upload and search own templates (PDB or mmCIF format, see [notes below](#custom_templates))\n",
        "\n",
        "if template_mode == \"pdb70\":\n",
        "  use_templates = True\n",
        "  custom_template_path = None\n",
        "elif template_mode == \"custom\":\n",
        "  custom_template_path = f\"{jobname}_template\"\n",
        "  os.mkdir(custom_template_path)\n",
        "  uploaded = files.upload()\n",
        "  use_templates = True\n",
        "  for fn in uploaded.keys():\n",
        "    os.rename(fn, f\"{jobname}_template/{fn}\")\n",
        "else:\n",
        "  custom_template_path = None\n",
        "  use_templates = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### MSA options (custom MSA upload, single sequence, pairing mode)\n",
        "msa_mode = \"MMseqs2 (UniRef+Environmental)\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
        "pair_mode = \"unpaired+paired\" #@param [\"unpaired+paired\",\"paired\",\"unpaired\"] {type:\"string\"}\n",
        "#@markdown - \"unpaired+paired\" = pair sequences from same species + unpaired MSA, \"unpaired\" = seperate MSA for each chain, \"paired\" - only use paired sequences.\n",
        "\n",
        "# decide which a3m to use\n",
        "if msa_mode.startswith(\"MMseqs2\"):\n",
        "  a3m_file = f\"{jobname}.a3m\"\n",
        "elif msa_mode == \"custom\":\n",
        "  a3m_file = f\"{jobname}.custom.a3m\"\n",
        "  if not os.path.isfile(a3m_file):\n",
        "    custom_msa_dict = files.upload()\n",
        "    custom_msa = list(custom_msa_dict.keys())[0]\n",
        "    header = 0\n",
        "    import fileinput\n",
        "    for line in fileinput.FileInput(custom_msa,inplace=1):\n",
        "      if line.startswith(\">\"):\n",
        "         header = header + 1\n",
        "      if not line.rstrip():\n",
        "        continue\n",
        "      if line.startswith(\">\") == False and header == 1:\n",
        "         query_sequence = line.rstrip()\n",
        "      print(line, end='')\n",
        "\n",
        "    os.rename(custom_msa, a3m_file)\n",
        "    queries_path=a3m_file\n",
        "    print(f\"moving {custom_msa} to {a3m_file}\")\n",
        "else:\n",
        "  a3m_file = f\"{jobname}.single_sequence.a3m\"\n",
        "  with open(a3m_file, \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence)"
      ],
      "metadata": {
        "id": "C2_sh2uAonJH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Advanced settings\n",
        "model_type = \"auto\" #@param [\"auto\", \"AlphaFold2-ptm\", \"AlphaFold2-multimer-v1\", \"AlphaFold2-multimer-v2\"]\n",
        "#@markdown - \"auto\" = protein structure prediction using \"AlphaFold2-ptm\" and complex prediction \"AlphaFold-multimer-v2\". For complexes \"AlphaFold-multimer-v[1,2]\" and \"AlphaFold-ptm\" can be used.\n",
        "num_recycles = 3 #@param [1,3,6,12,24,48] {type:\"raw\"}\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown -  if the save_to_google_drive option was selected, the result zip will be uploaded to your Google Drive\n",
        "dpi = 200 #@param {type:\"integer\"}\n",
        "#@markdown - set dpi for image resolution\n",
        "\n",
        "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form.\n",
        "\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")"
      ],
      "metadata": {
        "id": "ADDuaolKmjGW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccGdbe_Pmt9",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad55d42-d569-42ab-a836-8c398840a6b7",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_templates\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\n",
        "  # high risk high gain\n",
        "  pip install -q \"jax[cuda11_cudnn805]>=0.3.8,<0.4\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniconda3-latest-Linux-x86_64.sh\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=3.7 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  conda install -y -q -c conda-forge openmm=7.5.1 python=3.7 pdbfixer 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]\rExtracting : ncurses-6.3-h7f8727e_2.conda:   0%|          | 0/40 [00:00<?, ?it/s]\rExtracting : ncurses-6.3-h7f8727e_2.conda:   2%|▎         | 1/40 [00:00<00:07,  5.03it/s]\rExtracting : cryptography-36.0.0-py39h9ce1e76_0.conda:   2%|▎         | 1/40 [00:00<00:07,  5.03it/s]\rExtracting : libstdcxx-ng-9.3.0-hd4cf53a_17.conda:   5%|▌         | 2/40 [00:00<00:07,  5.03it/s]    \rExtracting : pycparser-2.21-pyhd3eb1b0_0.conda:   8%|▊         | 3/40 [00:00<00:07,  5.03it/s]   \rExtracting : pycparser-2.21-pyhd3eb1b0_0.conda:  10%|█         | 4/40 [00:00<00:02, 13.90it/s]\rExtracting : ca-certificates-2022.3.29-h06a4308_1.conda:  10%|█         | 4/40 [00:00<00:02, 13.90it/s]\rExtracting : brotlipy-0.7.0-py39h27cfd23_1003.conda:  12%|█▎        | 5/40 [00:00<00:02, 13.90it/s]    \rExtracting : setuptools-61.2.0-py39h06a4308_0.conda:  15%|█▌        | 6/40 [00:00<00:02, 13.90it/s]\rExtracting : openssl-1.1.1n-h7f8727e_0.conda:  18%|█▊        | 7/40 [00:00<00:02, 13.90it/s]       \rExtracting : xz-5.2.5-h7b6447c_0.conda:  20%|██        | 8/40 [00:00<00:02, 13.90it/s]      \rExtracting : xz-5.2.5-h7b6447c_0.conda:  22%|██▎       | 9/40 [00:00<00:01, 19.90it/s]\rExtracting : yaml-0.2.5-h7b6447c_0.conda:  22%|██▎       | 9/40 [00:00<00:01, 19.90it/s]\rExtracting : _libgcc_mutex-0.1-main.conda:  25%|██▌       | 10/40 [00:00<00:01, 19.90it/s]\rExtracting : six-1.16.0-pyhd3eb1b0_1.conda:  28%|██▊       | 11/40 [00:00<00:01, 19.90it/s]\rExtracting : ruamel_yaml-0.15.100-py39h27cfd23_0.conda:  30%|███       | 12/40 [00:00<00:01, 19.90it/s]\rExtracting : urllib3-1.26.8-pyhd3eb1b0_0.conda:  32%|███▎      | 13/40 [00:00<00:01, 19.90it/s]        \rExtracting : requests-2.27.1-pyhd3eb1b0_0.conda:  35%|███▌      | 14/40 [00:00<00:01, 19.90it/s]\rExtracting : pip-21.2.4-py39h06a4308_0.conda:  38%|███▊      | 15/40 [00:00<00:01, 19.90it/s]   \rExtracting : pyopenssl-22.0.0-pyhd3eb1b0_0.conda:  40%|████      | 16/40 [00:00<00:01, 19.90it/s]\rExtracting : pyopenssl-22.0.0-pyhd3eb1b0_0.conda:  42%|████▎     | 17/40 [00:00<00:00, 34.05it/s]\rExtracting : idna-3.3-pyhd3eb1b0_0.conda:  42%|████▎     | 17/40 [00:00<00:00, 34.05it/s]        \rExtracting : readline-8.1.2-h7f8727e_1.conda:  45%|████▌     | 18/40 [00:00<00:00, 34.05it/s]\rExtracting : charset-normalizer-2.0.4-pyhd3eb1b0_0.conda:  48%|████▊     | 19/40 [00:00<00:00, 34.05it/s]\rExtracting : cffi-1.15.0-py39hd667e15_1.conda:  50%|█████     | 20/40 [00:00<00:00, 34.05it/s]           \rExtracting : cffi-1.15.0-py39hd667e15_1.conda:  52%|█████▎    | 21/40 [00:00<00:00, 31.77it/s]\rExtracting : tqdm-4.63.0-pyhd3eb1b0_0.conda:  52%|█████▎    | 21/40 [00:00<00:00, 31.77it/s]  \rExtracting : conda-4.12.0-py39h06a4308_0.conda:  55%|█████▌    | 22/40 [00:01<00:00, 31.77it/s]\rExtracting : sqlite-3.38.2-hc218d9a_0.conda:  57%|█████▊    | 23/40 [00:01<00:00, 31.77it/s]   \rExtracting : pycosat-0.6.3-py39h27cfd23_0.conda:  60%|██████    | 24/40 [00:01<00:00, 31.77it/s]\rExtracting : pycosat-0.6.3-py39h27cfd23_0.conda:  62%|██████▎   | 25/40 [00:01<00:00, 15.36it/s]\rExtracting : colorama-0.4.4-pyhd3eb1b0_0.conda:  62%|██████▎   | 25/40 [00:01<00:00, 15.36it/s] \rExtracting : pysocks-1.7.1-py39h06a4308_0.conda:  65%|██████▌   | 26/40 [00:01<00:00, 15.36it/s]\rExtracting : wheel-0.37.1-pyhd3eb1b0_0.conda:  68%|██████▊   | 27/40 [00:01<00:00, 15.36it/s]   \rExtracting : tk-8.6.11-h1ccaba5_0.conda:  70%|███████   | 28/40 [00:01<00:00, 15.36it/s]     \rExtracting : python-3.9.12-h12debd9_0.conda:  72%|███████▎  | 29/40 [00:01<00:00, 15.36it/s]\rExtracting : python-3.9.12-h12debd9_0.conda:  75%|███████▌  | 30/40 [00:01<00:00, 11.92it/s]\rExtracting : libgomp-9.3.0-h5101ec6_17.conda:  75%|███████▌  | 30/40 [00:01<00:00, 11.92it/s]\rExtracting : tzdata-2022a-hda174b7_0.conda:  78%|███████▊  | 31/40 [00:01<00:00, 11.92it/s]  \rExtracting : libgcc-ng-9.3.0-h5101ec6_17.conda:  80%|████████  | 32/40 [00:01<00:00, 11.92it/s]\rExtracting : conda-package-handling-1.8.1-py39h7f8727e_0.conda:  82%|████████▎ | 33/40 [00:01<00:00, 11.92it/s]\rExtracting : zlib-1.2.12-h7f8727e_1.conda:  85%|████████▌ | 34/40 [00:01<00:00, 11.92it/s]                     \rExtracting : libffi-3.3-he6710b0_2.conda:  88%|████████▊ | 35/40 [00:01<00:00, 11.92it/s] \rExtracting : ld_impl_linux-64-2.35.1-h7274673_9.conda:  90%|█████████ | 36/40 [00:01<00:00, 11.92it/s]\rExtracting : certifi-2021.10.8-py39h06a4308_2.conda:  92%|█████████▎| 37/40 [00:01<00:00, 11.92it/s]  \rExtracting : conda-content-trust-0.1.1-pyhd3eb1b0_0.conda:  95%|█████████▌| 38/40 [00:01<00:00, 11.92it/s]\rExtracting : _openmp_mutex-4.5-1_gnu.tar.bz2:  98%|█████████▊| 39/40 [00:01<00:00, 11.92it/s]             \r                                                                                             \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sztQyz29DIC",
        "cellView": "form"
      },
      "source": [
        "#@title Run Prediction\n",
        "\n",
        "import sys\n",
        "\n",
        "from colabfold.download import download_alphafold_params, default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from colabfold.batch import get_queries, run, set_model_type\n",
        "K80_chk = !nvidia-smi | grep \"Tesla K80\" | wc -l\n",
        "if \"1\" in K80_chk:\n",
        "  print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "  if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "    del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "  if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "from colabfold.colabfold import plot_protein\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and '/usr/local/lib/python3.7/site-packages/' not in sys.path:\n",
        "    sys.path.insert(0, '/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "def prediction_callback(unrelaxed_protein, length, prediction_result, input_features, type):\n",
        "  fig = plot_protein(unrelaxed_protein, Ls=length, dpi=150)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "result_dir=\".\"\n",
        "setup_logging(Path(\".\").joinpath(\"log.txt\"))\n",
        "queries, is_complex = get_queries(queries_path)\n",
        "model_type = set_model_type(is_complex, model_type)\n",
        "download_alphafold_params(model_type, Path(\".\"))\n",
        "run(\n",
        "    queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=use_templates,\n",
        "    custom_template_path=custom_template_path,\n",
        "    use_amber=use_amber,\n",
        "    msa_mode=msa_mode,    \n",
        "    model_type=model_type,\n",
        "    num_models=5,\n",
        "    num_recycles=num_recycles,\n",
        "    model_order=[1, 2, 3, 4, 5],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=Path(\".\"),\n",
        "    keep_existing_results=False,\n",
        "    recompile_padding=1.0,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=pair_mode,\n",
        "    stop_at_score=float(100),\n",
        "    prediction_callback=prediction_callback,\n",
        "    dpi=dpi\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK7X9T44pWb7",
        "cellView": "form"
      },
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "import py3Dmol\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from colabfold.colabfold import plot_plddt_legend\n",
        "rank_num = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
        "color = \"lDDT\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "\n",
        "jobname_prefix = \".custom\" if msa_mode == \"custom\" else \"\"\n",
        "if use_amber:\n",
        "  pdb_filename = f\"{jobname}{jobname_prefix}_relaxed_rank_{rank_num}_model_*.pdb\"\n",
        "else:\n",
        "  pdb_filename = f\"{jobname}{jobname_prefix}_unrelaxed_rank_{rank_num}_model_*.pdb\"\n",
        "\n",
        "pdb_file = glob.glob(pdb_filename)\n",
        "\n",
        "def show_pdb(rank_num=1, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
        "  model_name = f\"rank_{rank_num}\"\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
        "  view.addModel(open(pdb_file[0],'r').read(),'pdb')\n",
        "\n",
        "  if color == \"lDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    chains = len(queries[0][1]) + 1 if is_complex else 1\n",
        "    for n,chain,color in zip(range(chains),list(\"ABCDEFGH\"),\n",
        "                     [\"lime\",\"cyan\",\"magenta\",\"yellow\",\"salmon\",\"white\",\"blue\",\"orange\"]):\n",
        "      view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})  \n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "\n",
        "  view.zoomTo()\n",
        "  return view\n",
        "\n",
        "\n",
        "show_pdb(rank_num,show_sidechains, show_mainchains, color).show()\n",
        "if color == \"lDDT\":\n",
        "  plot_plddt_legend().show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11l8k--10q0C",
        "cellView": "form"
      },
      "source": [
        "#@title Plots {run: \"auto\"}\n",
        "from IPython.display import display, HTML\n",
        "import base64\n",
        "from html import escape\n",
        "\n",
        "# see: https://stackoverflow.com/a/53688522\n",
        "def image_to_data_url(filename):\n",
        "  ext = filename.split('.')[-1]\n",
        "  prefix = f'data:image/{ext};base64,'\n",
        "  with open(filename, 'rb') as f:\n",
        "    img = f.read()\n",
        "  return prefix + base64.b64encode(img).decode('utf-8')\n",
        "\n",
        "pae = image_to_data_url(f\"{jobname}{jobname_prefix}_PAE.png\")\n",
        "cov = image_to_data_url(f\"{jobname}{jobname_prefix}_coverage.png\")\n",
        "plddt = image_to_data_url(f\"{jobname}{jobname_prefix}_plddt.png\")\n",
        "display(HTML(f\"\"\"\n",
        "<style>\n",
        "  img {{\n",
        "    float:left;\n",
        "  }}\n",
        "  .full {{\n",
        "    max-width:100%;\n",
        "  }}\n",
        "  .half {{\n",
        "    max-width:50%;\n",
        "  }}\n",
        "  @media (max-width:640px) {{\n",
        "    .half {{\n",
        "      max-width:100%;\n",
        "    }}\n",
        "  }}\n",
        "</style>\n",
        "<div style=\"max-width:90%; padding:2em;\">\n",
        "  <h1>Plots for {escape(jobname)}</h1>\n",
        "  <img src=\"{pae}\" class=\"full\" />\n",
        "  <img src=\"{cov}\" class=\"half\" />\n",
        "  <img src=\"{plddt}\" class=\"half\" />\n",
        "</div>\n",
        "\"\"\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33g5IIegij5R",
        "cellView": "form"
      },
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "if msa_mode == \"custom\":\n",
        "  print(\"Don't forget to cite your custom MSA generation method.\")\n",
        "\n",
        "!zip -FSr $jobname\".result.zip\" config.json $jobname*\".json\" $jobname*\".a3m\" $jobname*\"relaxed_rank_\"*\".pdb\" \"cite.bibtex\" $jobname*\".png\"\n",
        "files.download(f\"{jobname}.result.zip\")\n",
        "\n",
        "if save_to_google_drive == True and drive:\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}